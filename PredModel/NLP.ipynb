{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25a8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import Counter\n",
    "from typing import *\n",
    "import time\n",
    "import logging\n",
    "import altair as alt\n",
    "import re\n",
    "import numpy.linalg as la\n",
    "import json\n",
    "import Models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy.random\n",
    "import spacy\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import LogisticRegression\n",
    "from scipy.signal import find_peaks\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "alt.data_transformers.disable_max_rows\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c88f8",
   "metadata": {},
   "source": [
    "# 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16fed277",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "w2v = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "df_sus_users = pd.read_csv(\"../Data/Network/NetworkUsers.csv\", sep=\"\\t\", index_col=\"user_id\")\n",
    "def tokenize(text):\n",
    "    tokens = nlp(\" \".join([token.lower() for token in re.sub(\"\\.|,|:|!|\\?|-|\\'\", \" \", text).split(\" \") if token.isalpha()]))\n",
    "    return [token.lemma_ for token in tokens]\n",
    "\n",
    "def embed(tokens):\n",
    "    def toVec(token):\n",
    "        try:\n",
    "            return w2v[token]\n",
    "        except Exception:\n",
    "            return w2v[\"unk\"]\n",
    "    return [toVec(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def rate(rating): # 0 is false\n",
    "    for kw in [\"false\", \"fire\", \"flop\", \"barely\"]:\n",
    "        if kw in rating.lower():\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"train.csv\", sep=\"\\t\", index_col=\"index\")\n",
    "    df_mis = df[df.Misinformation==1]\n",
    "    df_mis = df_mis.sample(int(0.9 * len(df_mis)))\n",
    "    df_true = df[df.Misinformation==0].sample(int(0.9 * len(df_mis)))\n",
    "    df = pd.concat([df_true, df_mis])\n",
    "    df[\"Statement\"] = df[\"Statement\"].apply(tokenize)\n",
    "    df[\"Embedding\"] = df[\"Statement\"].apply(embed)\n",
    "    df_val = df[~df.Source]\n",
    "    df_val = df_val.sample(int(len(df_val) * 0.5))\n",
    "    return {\"train\": df[~df.index.isin(df_val.index)], \"val\": df_val}\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d23c7",
   "metadata": {},
   "source": [
    "# 2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml(data, model: nn.Module, epochs: int=10, lr: float=1e-4):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    predictor = Models.Predictor(model, device)\n",
    "    labels = torch.Tensor(data[\"train\"].Misinformation.values)\n",
    "    features = data[\"train\"].Embedding.tolist()\n",
    "    features = [torch.from_numpy(np.array(fea)) for fea in features]\n",
    "    predictor.train(features, labels, epochs=epochs, lr=lr)\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Models.LSTM()\n",
    "predictor = pipeline_ml(data, lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"val\"].Embedding.tolist()\n",
    "features = [torch.from_numpy(np.array(fea)) for fea in features]\n",
    "lstm_pred = predictor.predict(features) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(data[\"val\"].Misinformation, lstm_pred>0.5)\n",
    "acc = accuracy_score(data[\"val\"].Misinformation, lstm_pred>0.5)\n",
    "prec = precision_score(data[\"val\"].Misinformation, lstm_pred>0.5)\n",
    "recall = recall_score(data[\"val\"].Misinformation, lstm_pred>0.5)\n",
    "lstm_res = {\"f1\": f1, \"acc\": acc, \"prec\": prec, \"recall\": recall}\n",
    "lstm_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a109a01",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LogisticRegression.Preprocessor()\n",
    "processor.buildVocabulary(data[\"train\"])\n",
    "matrix = processor.buildMatrix(data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b132e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression.LogisticRegression(processor)\n",
    "LogisticRegression.train(matrix, data[\"train\"][\"Misinformation\"].values, LR, lr=5e-4, epoch_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = LogisticRegression.predict(LR, data[\"val\"]) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(data[\"val\"].Misinformation, lr_pred>0.5)\n",
    "acc = accuracy_score(data[\"val\"].Misinformation, lr_pred>0.5)\n",
    "prec = precision_score(data[\"val\"].Misinformation, lr_pred>0.5)\n",
    "recall = recall_score(data[\"val\"].Misinformation, lr_pred>0.5)\n",
    "lr_res = {\"f1\": f1, \"acc\": acc, \"prec\": prec, \"recall\": recall}\n",
    "lr_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef2dff",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GovernorPred.pkl\", \"wb\") as f:\n",
    "    f.write(pickle.dumps({\"LSTM\": lstm, \"LR\": processor}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1a1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GovernorPred.pkl\", \"rb\") as f:\n",
    "    models = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3006a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Models.Predictor(models[\"LSTM\"])\n",
    "LR = LogisticRegression.LogisticRegression(models[\"LR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e950d",
   "metadata": {},
   "source": [
    "# 5. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e621f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: DtypeWarning: Columns (8,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 s, sys: 9.08 s, total: 42.2 s\n",
      "Wall time: 52.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tweets = pd.read_csv(\"../Data/Candidates/GovernorTweets.csv\", sep=\"\\t\", index_col=\"id\")\n",
    "df_tweets = df_tweets[df_tweets.content!=\"\"].dropna()\n",
    "govnor_tweets = df_tweets[df_tweets.credibility!=1]\n",
    "govnor_tweets = govnor_tweets.sample(int(len(govnor_tweets) * 0.25))\n",
    "label = (govnor_tweets[\"credibility\"] <= 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc493ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build Matrix: 15304it [00:00, 52405.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.14535391785610255,\n",
       " 'acc': 0.6165708311552536,\n",
       " 'prec': 0.10185752194325373,\n",
       " 'recall': 0.253685815963396}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pred = LogisticRegression.predict(LR, govnor_tweets) > 0.5\n",
    "f1 = f1_score(label, lr_pred>0.5)\n",
    "acc = accuracy_score(label, lr_pred>0.5)\n",
    "prec = precision_score(label, lr_pred>0.5)\n",
    "recall = recall_score(label, lr_pred>0.5)\n",
    "lr_res = {\"f1\": f1, \"acc\": acc, \"prec\": prec, \"recall\": recall}\n",
    "lr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c5979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b52762d68724091a5b5f0a33fb976dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panda/anaconda3/envs/UM/lib/python3.9/site-packages/torch/nn/modules/rnn.py:761: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 58s, sys: 2.31 s, total: 2min\n",
      "Wall time: 2min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.2208536059616924,\n",
       " 'acc': 0.1733533716675379,\n",
       " 'prec': 0.12564821303433776,\n",
       " 'recall': 0.9115404168784952}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "features = govnor_tweets[\"content\"].apply(tokenize).apply(embed).tolist()\n",
    "features = [torch.from_numpy(np.array(fea)) for fea in features]\n",
    "lstm_pred = predictor.predict(features) > 0.5\n",
    "f1 = f1_score(label, lstm_pred>0.5)\n",
    "acc = accuracy_score(label, lstm_pred>0.5)\n",
    "prec = precision_score(label, lstm_pred>0.5)\n",
    "recall = recall_score(label, lstm_pred>0.5)\n",
    "lstm_res = {\"f1\": f1, \"acc\": acc, \"prec\": prec, \"recall\": recall}\n",
    "lstm_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4753f",
   "metadata": {},
   "source": [
    "### Tweets from incredible source not classified as misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0825a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misinformation\n",
    "bad_tweets[lstm_pred].sample(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.loc[[1518296660329201665, 1499864294170808332, 1516862042984095746,\n",
    "            1507126074882277381, 1518231318366244867, 1505706253888143362,\n",
    "            1509284007808172036, 1506148809725943808, 1501767346943414272,\n",
    "            1514341548892295183]].Statement.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fbc9a",
   "metadata": {},
   "source": [
    "### Tweets from incredible source not classified as misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True information\n",
    "bad_tweets[~lstm_pred].sample(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.loc[[1502046989483184135, 1498757468578582537, 1513529952834101255,\n",
    "            1502372547442077698, 1507041373421248514, 1510022055722467333,\n",
    "            1499040381463265282, 1502059266777178114, 1514618674501627904,\n",
    "            1503568426861838336]].Statement.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8bf30",
   "metadata": {},
   "source": [
    "### Tweets from credible source not classified as misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[lstm_pred].sample(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.loc[[1514322102303674370, 1500967005230305284, 1514267702252220418,\n",
    "            1515282667251634176, 1509875045677645828, 1499209915709239296,\n",
    "            1511243530202664960, 1501166881423728642, 1505590605438763011,\n",
    "            1500968967040602115]].Statement.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cce3e",
   "metadata": {},
   "source": [
    "### Tweets from credible source classified as misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cca9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[~lstm_pred].sample(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92cf864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.loc[[1499526834341490689, 1501715649046925315, 1512255934520864770,\n",
    "            1510012772712652802, 1509660956653146113, 1510813035526565889,\n",
    "            1517331816398548992, 1518945587479166976, 1514944616709115904,\n",
    "            1506400714544893954]].Statement.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[lstm_pred][\"Statement\"].apply(lambda x:len(x.split(\" \"))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a041df",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[~lstm_pred][\"Statement\"].apply(lambda x:len(x.split(\" \"))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be834c0",
   "metadata": {},
   "source": [
    "# 6. Use model to detect peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(governor: str, method: str=\"lstm\", emotion: str=\"anger\"):\n",
    "    emotions = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "    emotion = emotions.index(emotion)\n",
    "    if method == \"lstm\":\n",
    "        features = df_gov[\"Statement\"].apply(tokenize).apply(embed).tolist()\n",
    "        features = [torch.from_numpy(np.array(fea)) for fea in features]\n",
    "        lstm_pred = predictor.predict(features) > 0.5\n",
    "        df_gov[\"pred\"] = lstm_pred\n",
    "    elif method == \"lr\":\n",
    "        df_gov[\"pred\"] = (LogisticRegression.predict(LR, df_gov) > 0.5).values\n",
    "    elif method == \"emotion\":\n",
    "        df_gov[\"pred\"] = [res[emotion][\"score\"] for res in classifier(df_gov[\"Statement\"].tolist())]\n",
    "    return df_gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = detect_peaks('Lee Zeldin', \"emotion\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct = res.groupby([\"date\"])[\"pred\"].sum() / res.groupby([\"date\"])[\"pred\"].count()\n",
    "pct = res.groupby([\"date\"])[\"pred\"].mean()\n",
    "pct = (pct - pct.min()) / (pct.max() - pct.min()) * 100\n",
    "def detect_peak(counts: pd.Series):\n",
    "    prominence = 1.5 * (np.percentile(counts, 75) - np.percentile(counts, 25))\n",
    "    peaks_indexes, _ = find_peaks(counts, prominence = prominence)\n",
    "    return peaks_indexes\n",
    "pct.iloc[detect_peak(pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f872f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "governors = ['Stacey Abrams', 'Josh Shapiro', 'Charlie Crist', 'Katie Hobbs', 'Lee Zeldin']\n",
    "peaks = dict()\n",
    "for governor in governors[-1:]:\n",
    "    res = detect_peaks(governor, \"lr\")\n",
    "    pct = res.groupby([\"date\"])[\"pred\"].sum() / res.groupby([\"date\"])[\"pred\"].count()\n",
    "    pct = (pct - pct.min()) / (pct.max() - pct.min()) * 100\n",
    "    def detect_peak(counts: pd.Series):\n",
    "        prominence = 1.5 * (np.percentile(counts, 75) - np.percentile(counts, 25))\n",
    "        peaks_indexes, _ = find_peaks(counts, prominence = prominence)\n",
    "        return peaks_indexes\n",
    "    peaks[governor] = pct.iloc[detect_peak(pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73531b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct.iloc[detect_peak(pct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f98cfb",
   "metadata": {},
   "source": [
    "# 7. Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a04624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = pd.read_csv(\"../Data/Candidates/GovernorTweets.csv\", index_col=\"Date\", sep=\"\\t\")\n",
    "feature_cols = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "def load_sa_data(ratio: float=0.8, test_type: str=\"user\"):\n",
    "    if test_type == \"user\":\n",
    "        df_sus = df_emotion[df_emotion.author_id.isin(df_sus_users.index)] \n",
    "    else:\n",
    "        df_sus = df_emotion[df_emotion.credibility==0]\n",
    "    df_clean = df_emotion[~df_emotion.index.isin(df_sus)]\n",
    "    df_sus[\"label\"], df_clean[\"label\"] = 1, 0\n",
    "    df_sus_train = df_sus.sample(frac=ratio)\n",
    "    df_clean_train = df_clean.sample(frac=ratio)\n",
    "    size = min(len(df_sus_train), len(df_clean_train))\n",
    "    df_train = pd.concat([df_sus_train.sample(size), df_clean_train.sample(size)])\n",
    "    df_val = pd.concat([df_sus, df_clean])\n",
    "    df_val = df_val[~df_val.id.isin(df_train.id)]\n",
    "    data = {\"train\": df_train[feature_cols + [\"label\"]], \"val\": df_val[feature_cols + [\"label\"]]}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d538fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Allen B. West', 'Andrew Giuliani', \"Beto O'Rourke\",\n",
       "       'Bob Stefanowski', 'Brad Little', 'Brian Dahle', 'Brian Kemp',\n",
       "       'Chad Prather', 'Charlie Crist', 'Dan Cox', 'Darren Bailey',\n",
       "       'David Perdue', 'David White', 'Delilah Barrios', 'Doc Washburn',\n",
       "       'Doug Mastriano', 'Greg Abbott', 'Heidi Ganahl', 'Henry McMaster',\n",
       "       'J.B. Pritzker', 'Janet T. Mills', 'Jesse Sullivan', 'Jim Renacci',\n",
       "       'Josh Shapiro', 'Joy Hofmeister', 'Jumaane Williams',\n",
       "       'Kandiss Taylor', 'Kathy Hochul', 'Katie Hobbs', 'Kerry McQuisten',\n",
       "       'Kevin Stitt', 'Kim Reynolds', 'Kristi L. Noem', 'Laura Kelly',\n",
       "       'Lee Zeldin', 'Marc Thielman', 'Marco Lopez', 'Matt Brown',\n",
       "       'Matt Salmon', 'Maura Healey', 'Michelle Lujan Grisham',\n",
       "       'Nan Whaley', 'Ned Lamont', 'Nikki Fried', 'Paul Morgan',\n",
       "       'Rebecca Dow', 'Rebecca Kleefisch', 'Richard Michael DeWine',\n",
       "       'Rob Astorino', 'Ron DeSantis', 'Russell Diamond',\n",
       "       'Sarah Huckabee Sanders', 'Sonia Chang-Diaz', 'Stacey Abrams',\n",
       "       'Stan Pulliam', 'Steve Sisolak', 'Timothy Ramthun', 'Tina Kotek',\n",
       "       'Tom Suozzi', 'Tony Evers', 'Tudor Dixon'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion.Candidates.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3276ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair \n",
    "\n",
    "def detect_peak(counts: pd.Series, iqr: float = 1.5):\n",
    "    if counts.empty:\n",
    "        return list()\n",
    "    prominence = iqr * (np.percentile(counts, 75) - np.percentile(counts, 25))\n",
    "    peaks_indexes, _ = find_peaks(counts, prominence=prominence)\n",
    "    return peaks_indexes\n",
    "\n",
    "def plot_peak(df_counts: pd.DataFrame, field: str):\n",
    "    df_counts[\"Counts\"] = df_counts[field] / df_counts[field].max()\n",
    "    df_counts = df_counts[[\"Counts\", \"Date\"]]\n",
    "    df_counts[\"Date\"] = pd.to_datetime(df_counts[\"Date\"].astype(str))\n",
    "    chart = alt.Chart(df_counts).mark_line().encode(\n",
    "        y=alt.Y(\"Counts:Q\"),\n",
    "        x=alt.X(\"Date:T\"),\n",
    "        tooltip=[\"Counts:Q\", \"Date:T\"]\n",
    "    )\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "808901b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>anger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20220306</td>\n",
       "      <td>0.270363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20220401</td>\n",
       "      <td>0.249340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20220408</td>\n",
       "      <td>0.308686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20220410</td>\n",
       "      <td>0.272355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20220415</td>\n",
       "      <td>0.301779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     anger\n",
       "5   20220306  0.270363\n",
       "31  20220401  0.249340\n",
       "38  20220408  0.308686\n",
       "40  20220410  0.272355\n",
       "45  20220415  0.301779"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_emotion[df_emotion[\"Candidates\"]==\"Greg Abbott\"].groupby([\"Date\"])[\"anger\"].mean().reset_index()\n",
    "df_tmp.iloc[detect_peak(df_tmp[\"anger\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3157f",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6e0dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17321/3839116124.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sus[\"label\"], df_clean[\"label\"] = 1, 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger       0.139366\n",
      "disgust     0.152155\n",
      "fear        0.144602\n",
      "joy         0.144269\n",
      "neutral     0.137333\n",
      "sadness     0.140775\n",
      "surprise    0.141500\n",
      "dtype: float64\n",
      "CPU times: user 52.6 s, sys: 2.89 s, total: 55.5 s\n",
      "Wall time: 55.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0026531852407052662,\n",
       " 'acc': 0.6045953279569638,\n",
       " 'prec': 0.0013296230589710648,\n",
       " 'recall': 0.5820504421880118}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test on suspicious users\n",
    "data = load_sa_data()\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(data[\"train\"][feature_cols], data[\"train\"][\"label\"])\n",
    "rf_pred = rf.predict(data[\"val\"][feature_cols])\n",
    "print(pd.Series(rf.feature_importances_, index=feature_cols))\n",
    "Models.cal_metrics(rf_pred, data[\"val\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc60ea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17321/3839116124.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sus[\"label\"], df_clean[\"label\"] = 1, 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger       0.143126\n",
      "disgust     0.128496\n",
      "fear        0.160929\n",
      "joy         0.132691\n",
      "neutral     0.125480\n",
      "sadness     0.167031\n",
      "surprise    0.142245\n",
      "dtype: float64\n",
      "CPU times: user 36.3 s, sys: 2.59 s, total: 38.9 s\n",
      "Wall time: 38.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.00384708767557984,\n",
       " 'acc': 0.8438570452063956,\n",
       " 'prec': 0.0019289533634944632,\n",
       " 'recall': 0.6859060402684564}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test on suspicious domain\n",
    "data = load_sa_data(test_type=\"domain\")\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(data[\"train\"][feature_cols], data[\"train\"][\"label\"])\n",
    "rf_pred = rf.predict(data[\"val\"][feature_cols])\n",
    "print(pd.Series(rf.feature_importances_, index=feature_cols))\n",
    "Models.cal_metrics(rf_pred, data[\"val\"][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676701d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "600456c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_sa(data, model: nn.Module, epochs: int=5, lr: float=1e-4):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    feature_cols = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "    predictor = Models.Predictor(model, device)\n",
    "    labels = torch.Tensor(data[\"train\"].label.values)\n",
    "    features = [torch.from_numpy(fea) for fea in data[\"train\"][feature_cols].values.astype(np.float32)]\n",
    "    predictor.train(features, labels, epochs=epochs, lr=lr)\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa36236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a6d7be05604336a2c24ef01af393e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/337873 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0017919663133989404,\n",
       " 'acc': 0.0008967866624441728,\n",
       " 'prec': 0.0008967866624441728,\n",
       " 'recall': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on suspicious users\n",
    "data = load_sa_data()\n",
    "model = Models.LogisticRegression(7)\n",
    "predictor = pipeline_sa(data=data, model=model)\n",
    "df_val = data[\"val\"].sample(frac=0.1)\n",
    "lr_pred = predictor.predict(torch.from_numpy(df_val[feature_cols].values.astype(np.float32)))\n",
    "Models.cal_metrics(lr_pred, df_val[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bbe3376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17321/3839116124.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sus[\"label\"], df_clean[\"label\"] = 1, 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e854b169a344fc937a8eeb8d66b917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84754db823e44c9ba79c8b11e636ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b600461e6c14ac9be3cb2a948b41c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bfff819590426496942aab2db8fb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b6c3014a5047e7b9f141e178177eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b33078073142beb0e4a857118cc04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c83d500ec9b433d8a758ad3edc6122f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/338965 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0009505278938470862,\n",
       " 'acc': 0.07597539568982048,\n",
       " 'prec': 0.0004754975172008833,\n",
       " 'recall': 0.9675324675324676}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on suspicious domain\n",
    "data = load_sa_data(test_type=\"domain\")\n",
    "model = Models.LogisticRegression(7)\n",
    "predictor = pipeline_sa(data=data, model=model)\n",
    "df_val = data[\"val\"].sample(frac=0.1)\n",
    "lr_pred = predictor.predict(torch.from_numpy(df_val[feature_cols].values.astype(np.float32)))\n",
    "Models.cal_metrics(lr_pred, df_val[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e4d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
